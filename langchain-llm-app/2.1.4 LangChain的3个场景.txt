

LangChain 是在问答系统、数据处理与管理、自动问答与客服机器人这3个场景下。

第1个场景是问答系统。
     问答系统已经成为许多LLM应用的重要组成部分，从简单的搜索工具到复杂的知识库查询工具。

第2个场景是数据处理与管理，如 RAG。
     RAG结合了检索和生成两个阶段，为用户提供了更为精准和富有深度的回答。
     LangChain采用了LEDVR工作流，实现了RAG的功能。
     WebBaseLoader，从外部数据源导人所需的数据。接着，数据会被传输到嵌人包装器，如OpenAIEmbeddings中。
     这一步的主要目的是将每一份文档转化为一个能够在机器学习模型中使用的向量。
      这个向量能够捕获文档的主要特征，使得后续的处理更为高效。

     LangChain 中引人了分块转化步骤。通过使用如RecursiveCharacterTextSpliter 这样的工具，文档被切割成更小的数据块。
     这不仅提高了处理速度，还使得每一个数据块都能得到更为精准的处理。
     当所有的数据块都被处理完毕，它们会被存储到向量存储系统，如FAISS中。
     这个存储系统能够确保数据的安全，同时也能提供一个高效的查询接口。
     最后，检索器(如ConversationalRetrievalChain)被用来从向量存储系统中检索相关的文档。
     这一步结合了用户查询和向量存储系统中的数据，为用户提供了最为相关的回答。

第3个场景是自动问答与客服机器人。






